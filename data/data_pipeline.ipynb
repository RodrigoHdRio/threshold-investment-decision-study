{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "Load fundamentals, download prices, and build the modeling panel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compustat_factors(compustat_csv_path):\n",
    "    raw_fundamentals = pd.read_csv(compustat_csv_path)\n",
    "    raw_fundamentals = normalize_column_names(raw_fundamentals)\n",
    "    validate_required_columns(raw_fundamentals, REQUIRED_COMPUSTAT_COLUMNS)\n",
    "\n",
    "    fundamentals = (\n",
    "        raw_fundamentals[REQUIRED_COMPUSTAT_COLUMNS]\n",
    "        .rename(columns={\"tic\": \"ticker\"})\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    fundamentals[NUMERIC_COMPUSTAT_COLUMNS] = fundamentals[NUMERIC_COMPUSTAT_COLUMNS].apply(\n",
    "        pd.to_numeric,\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "\n",
    "    fundamentals = fundamentals.dropna(\n",
    "        subset=[\"ticker\", \"fyear\", \"revenue\", \"net_income\", \"stockholders_equity\"]\n",
    "    )\n",
    "\n",
    "    fundamentals[\"ticker\"] = fundamentals[\"ticker\"].astype(str).str.replace(\".\", \"-\", regex=False)\n",
    "    fundamentals = fundamentals.sort_values([\"ticker\", \"fyear\"]).reset_index(drop=True)\n",
    "\n",
    "    fundamentals[\"revenue_growth\"] = fundamentals.groupby(\"ticker\")[\"revenue\"].pct_change()\n",
    "    fundamentals[\"roe\"] = fundamentals[\"net_income\"] / fundamentals[\"stockholders_equity\"]\n",
    "    fundamentals[\"availability_date\"] = pd.to_datetime(\n",
    "        (fundamentals[\"fyear\"].astype(int) + 1).astype(str) + \"-01-01\"\n",
    "    )\n",
    "\n",
    "    factor_dataframe = fundamentals[[\"ticker\", \"availability_date\", \"revenue_growth\", \"roe\"]].copy()\n",
    "    ticker_universe = sorted(factor_dataframe[\"ticker\"].dropna().unique())\n",
    "    return factor_dataframe, ticker_universe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_adjusted_close_prices(ticker_universe, start_date, end_date, use_threads=False):\n",
    "    if not ticker_universe:\n",
    "        raise ValueError(\"Ticker universe is empty.\")\n",
    "\n",
    "    downloaded_price_chunks = []\n",
    "    for ticker_chunk in split_into_chunks(ticker_universe, PRICE_DOWNLOAD_CHUNK_SIZE):\n",
    "        try:\n",
    "            chunk_prices = yf.download(\n",
    "                ticker_chunk,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                auto_adjust=False,\n",
    "                group_by=\"column\",\n",
    "                progress=False,\n",
    "                threads=use_threads,\n",
    "            )\n",
    "        except Exception as error:\n",
    "            print(f\"Warning: download failed for chunk starting {ticker_chunk[0]}: {error}\")\n",
    "            continue\n",
    "\n",
    "        if chunk_prices is None or chunk_prices.empty:\n",
    "            print(f\"Warning: empty data for chunk starting {ticker_chunk[0]}\")\n",
    "            continue\n",
    "\n",
    "        downloaded_price_chunks.append(chunk_prices)\n",
    "\n",
    "    if not downloaded_price_chunks:\n",
    "        raise RuntimeError(\"No price data returned from Yahoo Finance.\")\n",
    "\n",
    "    merged_prices = pd.concat(downloaded_price_chunks, axis=1)\n",
    "    merged_prices = merged_prices.loc[:, ~merged_prices.columns.duplicated()]\n",
    "    adjusted_close_prices = extract_price_field(merged_prices).dropna(axis=1, how=\"all\")\n",
    "\n",
    "    if adjusted_close_prices.empty:\n",
    "        raise RuntimeError(\"Adjusted close matrix is empty after cleaning.\")\n",
    "\n",
    "    return adjusted_close_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_monthly_feature_panel(adjusted_close_prices):\n",
    "    daily_returns = adjusted_close_prices.pct_change()\n",
    "    trailing_volatility_60d = daily_returns.rolling(window=60).std().shift(1)\n",
    "\n",
    "    monthly_close_prices = adjusted_close_prices.resample(\"ME\").last()\n",
    "    monthly_close_prices.index.name = \"month_end\"\n",
    "    monthly_close_prices.columns.name = \"ticker\"\n",
    "\n",
    "    monthly_volatility = trailing_volatility_60d.reindex(monthly_close_prices.index, method=\"ffill\")\n",
    "    monthly_volatility.index.name = \"month_end\"\n",
    "    monthly_volatility.columns.name = \"ticker\"\n",
    "\n",
    "    momentum_6_12 = (monthly_close_prices.shift(6) / monthly_close_prices.shift(12)) - 1\n",
    "    momentum_6_12.index.name = \"month_end\"\n",
    "    momentum_6_12.columns.name = \"ticker\"\n",
    "\n",
    "    one_month_forward_return = (monthly_close_prices.shift(-1) / monthly_close_prices) - 1\n",
    "    one_month_forward_return.index.name = \"month_end\"\n",
    "    one_month_forward_return.columns.name = \"ticker\"\n",
    "\n",
    "    monthly_panel = (\n",
    "        monthly_close_prices.stack().rename(\"adj_close\").to_frame()\n",
    "        .join(monthly_volatility.stack().rename(\"vol_60\"))\n",
    "        .join(momentum_6_12.stack().rename(\"momentum_6_12\"))\n",
    "        .join(one_month_forward_return.stack().rename(\"target_return\"))\n",
    "        .reset_index()\n",
    "        .sort_values([\"ticker\", \"month_end\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return monthly_panel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_features_with_fundamentals(monthly_panel, factor_dataframe):\n",
    "    sorted_monthly_panel = monthly_panel.sort_values([\"month_end\", \"ticker\"]).reset_index(drop=True)\n",
    "    sorted_factor_dataframe = factor_dataframe.sort_values([\"availability_date\", \"ticker\"]).reset_index(drop=True)\n",
    "\n",
    "    modeling_panel = pd.merge_asof(\n",
    "        sorted_monthly_panel,\n",
    "        sorted_factor_dataframe,\n",
    "        left_on=\"month_end\",\n",
    "        right_on=\"availability_date\",\n",
    "        by=\"ticker\",\n",
    "        direction=\"backward\",\n",
    "    )\n",
    "\n",
    "    required_model_columns = MODEL_FEATURE_COLUMNS + [\"target_return\"]\n",
    "    modeling_panel = modeling_panel.dropna(subset=required_model_columns)\n",
    "    modeling_panel = modeling_panel.sort_values([\"ticker\", \"month_end\"]).reset_index(drop=True)\n",
    "\n",
    "    if modeling_panel.empty:\n",
    "        raise ValueError(\"Modeling panel is empty after merging and filtering.\")\n",
    "\n",
    "    return modeling_panel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_modeling_panel(modeling_panel, minimum_observations_per_month=100):\n",
    "    print(f\"Rows in final panel: {len(modeling_panel)}\")\n",
    "    print(f\"Unique months: {modeling_panel['month_end'].nunique()}\")\n",
    "    print(\"Missing values by column:\")\n",
    "    print(modeling_panel.isna().sum())\n",
    "\n",
    "    monthly_observation_counts = modeling_panel[\"month_end\"].value_counts().sort_index()\n",
    "    low_count_months = monthly_observation_counts[\n",
    "        monthly_observation_counts < minimum_observations_per_month\n",
    "    ]\n",
    "\n",
    "    if not low_count_months.empty:\n",
    "        print(f\"Warning: months with fewer than {minimum_observations_per_month} observations:\")\n",
    "        print(low_count_months)\n",
    "\n",
    "    return modeling_panel.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_pipeline(\n",
    "    compustat_csv_path,\n",
    "    fixed_end_date=None,\n",
    "    price_cache_path=None,\n",
    "    force_refresh=False,\n",
    "    download_threads=False,\n",
    "):\n",
    "    import os\n",
    "\n",
    "    factor_dataframe, ticker_universe = load_compustat_factors(compustat_csv_path)\n",
    "\n",
    "    first_fundamental_date = factor_dataframe[\"availability_date\"].min()\n",
    "    download_start_date = (first_fundamental_date - pd.Timedelta(days=LOOKBACK_BUFFER_DAYS)).date()\n",
    "    download_end_date = (\n",
    "        pd.Timestamp.today().date()\n",
    "        if fixed_end_date is None\n",
    "        else pd.Timestamp(fixed_end_date).date()\n",
    "    )\n",
    "\n",
    "    print(f\"Compustat tickers: {len(ticker_universe)}\")\n",
    "    print(f\"Price window: {download_start_date} to {download_end_date}\")\n",
    "\n",
    "    use_cache = bool(price_cache_path) and os.path.exists(price_cache_path) and not force_refresh\n",
    "    if use_cache:\n",
    "        adjusted_close_prices = pd.read_pickle(price_cache_path)\n",
    "        adjusted_close_prices.index = pd.to_datetime(adjusted_close_prices.index)\n",
    "        adjusted_close_prices.columns.name = \"ticker\"\n",
    "        print(f\"Loaded cached prices from {price_cache_path}\")\n",
    "    else:\n",
    "        adjusted_close_prices = download_adjusted_close_prices(\n",
    "            ticker_universe,\n",
    "            download_start_date,\n",
    "            download_end_date,\n",
    "            use_threads=download_threads,\n",
    "        )\n",
    "\n",
    "        if price_cache_path:\n",
    "            os.makedirs(os.path.dirname(price_cache_path), exist_ok=True)\n",
    "            adjusted_close_prices.to_pickle(price_cache_path)\n",
    "            print(f\"Saved price cache to {price_cache_path}\")\n",
    "\n",
    "    missing_tickers = sorted(set(ticker_universe) - set(adjusted_close_prices.columns))\n",
    "    if missing_tickers:\n",
    "        print(f\"Warning: Missing price data for {len(missing_tickers)} tickers: {missing_tickers[:10]}\")\n",
    "\n",
    "    monthly_panel = build_monthly_feature_panel(adjusted_close_prices)\n",
    "    modeling_panel = merge_features_with_fundamentals(monthly_panel, factor_dataframe)\n",
    "\n",
    "    print(f\"Downloaded/loaded adjusted-close prices for {adjusted_close_prices.shape[1]} tickers\")\n",
    "    print(f\"Panel rows (pre-fundamentals): {len(monthly_panel)}\")\n",
    "    print(f\"Panel rows (final): {len(modeling_panel)}\")\n",
    "    print(\n",
    "        \"Date range:\",\n",
    "        modeling_panel[\"month_end\"].min().date(),\n",
    "        \"to\",\n",
    "        modeling_panel[\"month_end\"].max().date(),\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"factor_dataframe\": factor_dataframe,\n",
    "        \"ticker_universe\": ticker_universe,\n",
    "        \"adjusted_close_prices\": adjusted_close_prices,\n",
    "        \"monthly_panel\": monthly_panel,\n",
    "        \"modeling_panel\": modeling_panel,\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}